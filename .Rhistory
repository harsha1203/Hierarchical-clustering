mydata <- input[,c(1,3:8)]
## the first column in mydata has university names
data <- mydata[,-1]
attach(data)
View(data)
View(data)
pcaObj<-princomp(data, cor = TRUE, scores = TRUE, covmat = NULL)
str(pcaObj)
summary(pcaObj)
loadings(pcaObj)
plot(pcaObj) # graph showing importance of principal components
biplot(pcaObj)
plot(cumsum(pcaObj$sdev*pcaObj$sdev)*100/(sum(pcaObj$sdev*pcaObj$sdev)),type="b")
pcaObj$scores
pcaObj$scores[,1:3]
View(pcaObj)
View(mydata)
# Top 3 pca scores
final<-cbind(input[,1],pcaObj$scores[,1:3])
View(final)
View(Salary_Data)
attach(Salary_Data)
View(Salary_Data)
#EDA
#1st business moments
mean(Salary_Data$YearsExperience`) #357071
#EDA
#1st business moments
mean(YearsExperience)
attach(Salary_Data)
View(Salary_Data)
Salary_Data <- read_csv("D:/Modules/Module 6 - SLR/Salary_Data.csv")
library(readr)
library(moments)
View(Salary_Data)
View(Salary_Data)
View(Salary_Data)
library(readr)
Salary_Data <- read_csv("D:/Modules/Module 6 - SLR/Salary_Data.csv")
View(Salary_Data)
View(Salary_Data)
Salary_Data <- read_csv("D:/Modules/Module 6 - SLR/Salary_Data.csv")
View(Salary_Data)
attach(Salary_Data)
#EDA
#1st business moments
mean(YearsExperience)
library(readr)
groceries <- read_csv("D:/Modules/module 15/groceries.csv")
View(groceries)
install.packages("arules")
data()
library(readr)
groceries <- read_csv("D:/Modules/module 15/groceries.csv")
View(groceries)
data("Groceries") # loading the Groceries Data
data("Groceries") # loading the Groceries Data
inspect(groceries[1:10]) # showing only top 10 transactions
class(Groceries) # Groceries is in transactions format
# Building rules using apriori algorithm
arules <- apriori(groceries, parameter = list(support=0.002,confidence=0.6,minlen=2))
# install.packages("arueslViz")
library("arulesViz") # for visualizing rules
install.packages("arueslViz")
library("arulesViz") # for visualizing rules
# Building rules using apriori algorithm
arules <- apriori(groceries, parameter = list(support=0.002,confidence=0.6,minlen=2))
arules
inspect(head(sort(arules,by="lift"))) # to view we use inspect
View(groceries)
library("arules") # Used for building association rules i.e. apriori algorithm
library(moments)
library(moments)
library(readr)
library(readr)
library(readr)
library(readr)
Salary_Data <- read_csv("D:/Modules/Module 6 - SLR/Salary_Data.csv")
View(Salary_Data)
attach(Salary_Data)
#EDA
#1st business moments
mean(YearsExperience) #5.31
mean(Salary_Data$Salary) #76003
median(Salary_Data$YearsExperience) #4.7
median(Salary_Data$Salary) #65237
# 2nd business moments
var(Salary_Data$YearsExperience) #8.053
var(Salary_Data$Salary)
sd(Salary_Data$YearsExperience) #2.83
sd(Salary_Data$Salary) #27414.43
range(Salary_Data$YearsExperience) #1.1 10.5
range(Salary_Data$Salary) #37731 122391
#different visulaizations
boxplot(Salary_Data) #no outliers
hist(Salary_Data$YearsExperience)
#different visulaizations
boxplot(Salary_Data) #no outliers
hist(Salary_Data$YearsExperience)
hist(Salary_Data$Salary)
library(moments)
library(readr)
library(readr)
Salary_Data <- read_csv("D:/Modules/Module 6 - SLR/Salary_Data.csv")
View(Salary_Data)
attach(Salary_Data)
## R Markdown
This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.
#different visulaizations
boxplot(Salary_Data) #no outliers
hist(Salary_Data$YearsExperience)
hist(Salary_Data$Salary)
#different visulaizations
boxplot(Salary_Data) #no outliers
hist(Salary_Data$YearsExperience)
hist(Salary_Data$Salary)
#3rd business moment
library(moments)
skewness(Salary_Data$YearsExperience) #positive skewness
skewness(Salary_Data$Salary) #positive skewness
#4th business moment
kurtosis(Salary_Data$YearsExperience) #positive kurtosis
kurtosis(Salary_Data$Salary)
#3rd business moment
library(moments)
skewness(Salary_Data$YearsExperience) #positive skewness
skewness(Salary_Data$Salary) #positive skewness
#4th business moment
kurtosis(Salary_Data$YearsExperience) #positive kurtosis
kurtosis(Salary_Data$Salary)
#Normal Quantile-Quantile Plot
qqnorm(Salary)
qqline(Salary)
#Normal Quantile-Quantile Plot
qqnorm(Salary)
qqline(Salary)
qqnorm(YearsExperience)##Normally distributed
qqline(YearsExperience)
attach(Salary_Data)
plot(YearsExperience,Salary) #positive relation
cor(YearsExperience,Salary)
qqnorm(Salary)
qqline(Salary)
qqnorm(YearsExperience)##Normally distributed
qqline(YearsExperience)
plot(YearsExperience,Salary) #positive relation
cor(YearsExperience,Salary)
#model building
model<- lm(YearsExperience~Salary)
summary (model)
#model building
model<- lm(YearsExperience~Salary)
summary (model)
#p is significant and r=0.95
confint(model,level = 0.95)
predict(model,interval="predict")
model$residuals
rmse<-sqrt(mean(model$residuals^2))
rmse  #0.578
#least RMSE value model is evualted
#p is significant and r=0.95
confint(model,level = 0.95)
predict(model,interval="predict")
model$residuals
rmse<-sqrt(mean(model$residuals^2))
rmse  #0.578
#model building
model<- lm(YearsExperience~Salary)
summary (model)
#p is significant and r=0.95
confint(model,level = 0.95)
predict(model,interval="predict")
model$residuals
rmse<-sqrt(mean(model$residuals^2))
rmse  #0.578
#least RMSE value model is evualted
#p is significant and r=0.95
confint(model,level = 0.95)
predict(model,interval="predict")
model$residuals
rmse<-sqrt(mean(model$residuals^2))
rmse  #0.578
model$residuals
rmse<-sqrt(mean(model$residuals^2))
rmse  #0.578
#least RMSE value model is evualted
View(Salary_Data)
library(moments)
library(readr)
library(readr)
Salary_Data <- read_csv("D:/Modules/Module 6 - SLR/Salary_Data.csv")
View(Salary_Data)
attach(Salary_Data)
#EDA
#1st business moments
mean(YearsExperience) #5.31
mean(Salary_Data$Salary) #76003
median(Salary_Data$YearsExperience) #4.7
median(Salary_Data$Salary) #65237
# 2nd business moments
var(Salary_Data$YearsExperience) #8.053
var(Salary_Data$Salary)
sd(Salary_Data$YearsExperience) #2.83
sd(Salary_Data$Salary) #27414.43
range(Salary_Data$YearsExperience) #1.1 10.5
range(Salary_Data$Salary) #37731 122391
EastWestAirlines<-read.xlsx("D:\Modules\Module 12)
EastWestAirlines<-read.xlsx("D:/Modules/Module 12/"EastWestAirlines.xlsx")
library(readxl)
EastWestAirlines <- read_excel("D:/Modules/Module 12/EastWestAirlines.xlsx")
View(EastWestAirlines)
View(EastWestAirlines)
summary(EastWestAirlines)
s
sum(is.na(EastWestAirlines))
attach(EastWestAirlines)
boxplot(EastWestAirlines$Balance)
str(EastWestAirlines)
EastWestAirlines <- read.table("D:/Modules/Module 12/EastWestAirlines.xlsx", quote="\"", comment.char="")
View(EastWestAirlines)
library(readr)
crime_data <- read_csv("D:/Modules/Module 12/crime_data.csv")
View(crime_data)
str(crime_data)
normalized_data<-scale(crime_data[,2:5]) #excluding the university name columnbefore normalizing
View(normalized_data)
d <- dist(normalized_data, method = "euclidean") # distance matrix
d
# Model Building
fit <- hclust(d, method="complete")
View(fit)
fit$labels
fit$dist.method
plot(fit) # display dendrogram
plot(fit, hang=-1)
groups <- cutree(fit, k=5) # cut tree into 5 clusters
class(groups)
rect.hclust(fit, k=5, border="red")
membership<-as.matrix(groups)
table(membership)
final <- data.frame(crime_data, membership)
#final <- cbind(mydata, membership)
View(final)
View(crime_data)
normalized_data<-scale(crime_data[,2:5]) #excluding the university name columnbefore normalizing
View(normalized_data)
View(normalized_data)
#explore setcolorder for repositioning the columns in R
# Also install the package "data.table"
install.packages("data.table")
#final <- cbind(mydata, membership)
View(final)
library(data.table)
setcolorder(final,c("membership"))
View(final)
write.csv(final, file="final11.csv")
setwd("D:\Modules\Module 12")
setwd("D:/Modules/Module 12")
getwd()
View(final)
#final <- cbind(mydata, membership)
View(final)
library(readr)
crime_data <- read_csv("D:/Modules/Module 12/crime_data.csv")
View(crime_data)
str(crime_data)
normalized_data<-scale(crime_data[,2:5]) #excluding the university name columnbefore normalizing
View(normalized_data)
d <- dist(normalized_data, method = "euclidean") # distance matrix
d
# Model Building
fit <- hclust(d, method="complete")
View(fit)
fit$labels
fit$dist.method
plot(fit) # display dendrogram
plot(fit, hang=-1)
groups <- cutree(fit, k=5) # cut tree into 5 clusters
class(groups)
?cutree
rect.hclust(fit, k=5, border="red")
?rect.hclust
membership<-as.matrix(groups)
table(membership)
final <- data.frame(crime_data, membership)
#final <- cbind(mydata, membership)
View(final)
##final1 <- final[,c(ncol(final),1:(ncol(final)-1))]
unlink('crime_cache', recursive = TRUE)
plot(fit) # display dendrogram
library(readr)
crime_data <- read_csv("D:/Modules/Module 12/crime_data.csv")
View(crime_data)
str(crime_data)
normalized_data<-scale(crime_data[,2:5]) #excluding the university name columnbefore normalizing
View(normalized_data)
d <- dist(normalized_data, method = "euclidean") # distance matrix
d
# Model Building
fit <- hclust(d, method="complete")
View(fit)
fit$labels
fit$dist.method
```{r pressure, echo=FALSE}
install.packages(readr)
library(readr)
crime_data <- read_csv("D:/Modules/Module 12/crime_data.csv")
View(crime_data)
plot(fit) # display dendrogram
plot(fit, hang=-1)
groups <- cutree(fit, k=5) # cut tree into 5 clusters
membership<-as.matrix(groups)
table(membership)
final <- data.frame(crime_data, membership)
#final <- cbind(mydata, membership)
View(final)
library(data.table)
setcolorder(final,c("membership"))
View(final)
crime_data <- read_csv("D:/Modules/Module 12/crime_data.csv")
View(crime_data)
normalized_data<-scale(crime_data[,2:5]) #excluding the university name columnbefore normalizing
View(normalized_data)
t
t
d
# Model Building
fit <- hclust(d, method="complete")
View(fit)
fit$labels
fit$dist.method
plot(fit) # display dendrogram
plot(fit, hang=-1)
groups <- cutree(fit, k=5) # cut tree into 5 clusters
class(groups)
rect.hclust(fit, k=5, border="red")
membership<-as.matrix(groups)
table(membership)
final <- data.frame(crime_data, membership)
View(final)
library(readxl)
library(readxl)
input <- read_excel(file.choose())
library(readr)
library(readr)
wine <- read_csv("D:/Modules/Module 14/wine.csv")
View(wine)
library(readr)
wine <- read_csv("D:/Modules/Module 14/wine.csv")
View(wine)
summary(cars)
View(wine)
## the first column in mydata has university names
View(wine[-1])
# mydata[-1] -> Considering only numerical values for applying PCA
data <- wine[-1]
attach(data)
cor(data)
pcaObj<-princomp(data, cor = TRUE, scores = TRUE, covmat = NULL)
str(pcaObj)
summary(pcaObj)
loadings(pcaObj)
plot(pcaObj) # graph showing importance of principal components
biplot(pcaObj)
# Showing the increase of variance with considering principal components
# Which helps in choosing number of principal components
plot(cumsum(pcaObj$sdev*pcaObj$sdev)*100/(sum(pcaObj$sdev*pcaObj$sdev)),type="b")
pcaObj$scores[,1:7] # Top 7 PCA Scores which represents the whole data
# cbind used to bind the data in column wise
# Considering top 3 principal component scores and binding them with mydata
data<-cbind(data,pcaObj$scores[,1:7])
View(data)
# preparing data for clustering (considering only pca scores as they represent the entire data)
clus_data<-wine[,14:20]
# Normalizing the data
norm_clus<-scale(clus_data) # Scale function is used to normalize data
# preparing data for clustering (considering only pca scores as they represent the entire data)
clus_data<-data[,14:20]
# Normalizing the data
norm_clus<-scale(clus_data) # Scale function is used to normalize data
dist1<-dist(norm_clus,method = "euclidean") # method for finding the distance
# Clustering the data using hclust function --> Hierarchical
fit1<-hclust(dist1,method="complete") # method here is complete linkage
plot(fit1) # Displaying Dendrogram
groups<-cutree(fit1,5) # Cutting the dendrogram for 5 clusters
membership_1<-as.matrix(groups) # cluster numbering
view(membership_1)
View(membership_1)
membership_1
final1<-cbind(membership_1,wine[-1]) # binding column wise with orginal data
View(final1)
final1<-cbind(membership_1,data) # binding column wise with orginal data
View(final1)
# Multinomial Logit Model
# packages required
require('mlogit')
require('nnet')
#In built dataset
data()
data(Mode)
head(Mode)
Mode <- read_csv("D:/Modules/Module 10 - Multinominal regression/mode.csv")
head(Mode)
tail(Mode)
View(Mode)
table(Mode$choice) # tabular representation of the Y categories
Mode.choice <- multinom(choice ~ cost.car + cost.carpool + cost.bus + cost.rail + time.car + time.carpool + time.bus + time.rail, data=Mode)
summary(Mode.choice)
Mode$choice  <- relevel(Mode$choice, ref= "carpool")  # change the baseline level
##### Significance of Regression Coefficients###
z <- summary(Mode.choice)$coefficients / summary(Mode.choice)$standard.errors
p_value <- (1-pnorm(abs(z),0,1))*2
summary(Mode.choice)$coefficients
p_value
# odds ratio
exp(coef(Mode.choice))
# predict probabilities
prob <- fitted(Mode.choice)
prob
class(prob)
prob <- data.frame(prob)
View(prob)
prob["pred"] <- NULL
# Custom function that returns the predicted value based on probability
get_names <- function(i){
return (names(which.max(i)))
}
pred_name <- apply(prob,1,get_names)
prob$pred <- pred_name
View(prob)
# Confusion matrix
table(pred_name,Mode$choice)
# confusion matrix visualization
barplot(table(pred_name,Mode$choice),beside = T,col=c("red","lightgreen","blue","orange"),legend=c("bus","car","carpool","rail"),main = "Predicted(X-axis) - Legends(Actual)",ylab ="count")
# Accuracy
mean(pred_name==Mode$choice) # 69.31 %
Mode <- read_csv("D:/Modules/Module 10 - Multinominal regression/mdata.csv")
head(Mode)
tail(Mode)
View(Mode)
Mode <- read_csv("D:/Modules/Module 10 - Multinominal regression/mdata.csv")
View(Mdata)
Mdata <- read_csv("D:/Modules/Module 10 - Multinominal regression/mdata.csv")
View(Mdata)
Mdata.program <- Mdata[;6:10]
Mdata.program <- Mdata[:6:10]
Mdata.program <- input[,c(3:8)]
Mdata.program <- Mdata[,c(3:8)]
Mdata.program <- Mdata[,c(6:10)]
Mdata.program
Mdata1 <- Mdata[,c(6:10)]
Mdata1
table(Mdata1$program) # tabular representation of the Y categories
table(Mdata1$prog) # tabular representation of the Y categories
View(Mdata1)
Mode.prog <- multinom(prog ~ read+write+math+science, data=Mdata1)
summary(Mode.prog)
##### Significance of Regression Coefficients###
z <- summary(Mode.prog)$coefficients / summary(Mode.prog)$standard.errors
p_value <- (1-pnorm(abs(z),0,1))*2
summary(Mode.prog)$coefficients
p_value
# odds ratio
exp(coef(Mode.choice))
# odds ratio
exp(coef(Mode.prog))
# predict probabilities
prob <- fitted(Mode.prog)
prob
class(prob)
prob <- data.frame(prob)
View(prob)
prob["pred"] <- NULL
# Custom function that returns the predicted value based on probability
get_names <- function(i){
return (names(which.max(i)))
}
pred_name <- apply(prob,1,get_names)
prob$pred <- pred_name
View(prob)
# Confusion matrix
table(pred_name,Mdata$prog)
# confusion matrix visualization
barplot(table(pred_name,Mdata$prog),beside = T,col=c("red","lightgreen","blue","orange"),legend=c("bus","car","carpool","rail"),main = "Predicted(X-axis) - Legends(Actual)",ylab ="count")
# confusion matrix visualization
barplot(table(pred_name,Mdata$prog),beside = T,col=c("red","lightgreen","blue","orange"),legend=c("academic","general","vocation"),main = "Predicted(X-axis) - Legends(Actual)",ylab ="count")
# Accuracy
mean(pred_name==Mdata$prog) # 69.31 %
#Installing and loading the libraries
install.packages("recommenderlab", dependencies=TRUE)
install.packages("Matrix")
library("recommenderlab")
library(caTools)
movie_rate_data <- read_csv("D:/Modules/Module16/Movie.csv")
movie_rate_data <- read_csv("D:/Modules/Module 16/Movie.csv")
movie_rate_data <- read_csv("D:/Modules/Module 16 - Recommender/Movie.csv")
View(movie_rate_data)
table(movie_rate_data$movie)
#metadata about the variable
str(movie_rate_data)
#rating distribution
hist(movie_rate_data$rating)
#the datatype should be realRatingMatrix inorder to build recommendation engine
movie_rate_data_matrix <- as(movie_rate_data, 'realRatingMatrix')
movie_recomm_model1 <- Recommender(movie_rate_data_matrix, method="POPULAR")
#the datatype should be realRatingMatrix inorder to build recommendation engine
movie_rate_data_matrix <- as(movie_rate_data, 'realRatingMatrix')
class(movie_rate_data)
#the datatype should be realRatingMatrix inorder to build recommendation engine
movie_rate_data_matrix <- as(movie_rate_data, 'realRatingMatrix')
#metadata about the variable
str(movie_rate_data)
